[![base model](https://img.shields.io/badge/ü§ó-base%20model-grey)](https://huggingface.co/baiges/CatGPT)
[![instruct model](https://img.shields.io/badge/ü§ó-instruct%20model-grey)](https://huggingface.co/baiges/CatGPT-IT)

# CatGPT

<div align="center">
  <img src="logo/CatGPT.jpg" alt="CatGPT Logo" style="width:50%; height:auto;">
</div>

## Table of Contents / Taula de Continguts

1. [Project Objective / Objectius del Projecte](#project-objective--objectius-del-projecte)
2. [Model Structure / Estructura del Model](#model-structure--estructura-del-model)
3. [Training Datasets / Datasets d'Entrenament](#training-datasets--datasets-dentrenament)
4. [Tokenizer](#tokenizer)
5. [Document Structure / Estructura dels Documents](#document-structure--estructura-dels-documents)
6. [How to Use the Model / Com Utilitzar el Model](#how-to-use-the-model--com-utilitzar-el-model)
7. [App Structure / Estructura de l'App](#app-structure--estructura-de-lapp)
   - [Overview of Parameters / Visi√≥ general dels Par√†metres](#overview-of-parameters--visi√≥-general-dels-par√†metres)
   - [Example Screenshots / Captures de Pantalla d'Exemple](#example-screenshots--captures-de-pantalla-dexemple)
8. [Installation / Instal¬∑laci√≥](#installation--installaci√≥)
9. [Contributing / Contribucions](#contributing--contribucions)
10. [License / Llic√®ncia](#license--llic√®ncia)
11. [Contact Information / Informaci√≥ de Contacte](#contact-information--informaci√≥-de-contacte)

## Project Objective / Objectius del Projecte

**English:**  
CatGPT is a Catalan natural language model created with the goal of providing a lightweight yet effective model that can continue sentences in Catalan. This project is designed to facilitate the generation of coherent and relevant text in Catalan. The model is primarily intended for educational purposes, offering a simple yet functional tool for exploring natural language processing in Catalan. Given its small size, the model does not aim for high performance but rather serves as an accessible resource for learning and experimentation. In addition to predicting the next words, the ultimate goal is to fine-tune the model so it can respond to messages, such as answering questions or following instructions.

**Catal√†:**  
CatGPT √©s un model de llenguatge natural en catal√†, creat amb l'objectiu de proporcionar un model lleuger per√≤ efectiu que pugui continuar oracions en catal√†. Aquest projecte est√† dissenyat per facilitar la generaci√≥ de text coherent i rellevant en catal√†. El model est√† pensat principalment per a usos educatius, oferint una eina senzilla per√≤ funcional per explorar el processament del llenguatge natural en catal√†. At√®s que la mida del model √©s redu√Øda, no t√© com a objectiu assolir un alt rendiment, sin√≥ servir com a recurs accessible per a l'aprenentatge i l'experimentaci√≥. A m√©s de predir les seg√ºents paraules, l'objectiu final √©s crear un model ajustat (finetuned) que pugui respondre a missatges, com ara preguntes o seguir instruccions.

## Model Structure / Estructura del Model

**English:**  
CatGPT is modeled after a structure similar to GPT-2 and features the following key specifications:

- **Parameters:** ~111 million  
- **Vocabulary Size:** 32,768 unique tokens (Catalan-specific)
- **Number of Layers:** 12
- **Attention Heads:** 8
- **Embedding Size:** 768
- **Block Size:** 1024 tokens

The model‚Äôs parameter count is primarily influenced by its specialized Catalan vocabulary. Despite being relatively compact, these design choices ensure efficient training and inference, providing satisfactory text generation quality within the Catalan language context.

**Catal√†:**  
CatGPT segueix una estructura similar a GPT-2 i presenta les seg√ºents especificacions clau:

- **Par√†metres:** ~111 milions  
- **Mida del Vocabulari:** 32.768 tokens √∫nics (adaptat al catal√†)
- **Nombre de Capes:** 12
- **Cap√ßals d'Atenci√≥:** 8
- **Mida dels Embeddings:** 768
- **Mida del Bloc:** 1024 tokens

El nombre de par√†metres est√† principalment influenciat pel vocabulari especialitzat en catal√†. Tot i ser relativament compacte, aquestes decisions de disseny asseguren un entrenament i una infer√®ncia eficients, oferint una qualitat de generaci√≥ de text satisfact√≤ria dins del context de la llengua catalana.

## Training Datasets / Datasets d'Entrenament

**English:**  
The model has been trained using various datasets, including:

- **Oscar:** A massive multilingual corpus with only Catalan text, including:
  - Catalan General Crawling: Obtained from scraping the 500 most popular .cat and .ad domains.
  - Catalan Government Crawling: Data collected from .gencat domains and subdomains of the Catalan government.
  - Existing public corpora: Including DOGC, CaWac, Open Subtitles, the Catalan Wikipedia, among others.
  - Catalan News Agency: News from the Catalan News Agency collected from March 2015 to October 2020.

- **Catalan_Textual Dataset:** A specifically created dataset covering a wide range of Catalan texts.

Due to the lack of high-quality Catalan content, we also created the **Patufet collection of datasets** using synthetic data generation, mainly produced with the Gemini Flash model. These datasets include:

  - **Patufet-Textbooks:** The primary dataset with around 300 million tokens, categorized by key sectors such as education, science, history, and culture, with submodels for kids, high school, general, college, and researchers.
  
  - **Patufet-QA (Question-Answering):** This dataset contains around 500k question-answer pairs, based on the Patufet-Textbooks dataset, to support question-answering capabilities.
  
  - **Patufet-PremiumText:** Created using GPT-4o to ensure high-quality content, this dataset contains approximately 6000 examples, including poems, stories, summaries, sentiment analysis, and more.
  
  - **Patufet-Human-Interactions:** Created using GPT-4o, this dataset focuses on quality content related to human interactions, such as greetings and curious questions, with fewer examples.

Other datasets, such as those for programming or instruction-following, were also created. However, these were not included in this version of the model, as they were deemed too advanced and could potentially reduce the model's effectiveness in tasks it could not fully comprehend.

The base model was trained with over 3000 million unique tokens, including the Oscar and Catalan Textual datasets. Once the model had learned the fundamental structure and usage of Catalan, it was further trained with the **Patufet-Textbooks** dataset to ensure a more varied and comprehensive understanding across multiple domains. This additional training greatly improved the model's versatility and depth.

For the instruction-based model, additional training was done using the question-answering and instruction datasets to enable it to respond effectively to messages and follow instructions.

**Catal√†:**  
El model ha estat entrenat utilitzant diversos datasets, incloent:

- **Oscar:** Un corpus multiling√ºe massiu amb nom√©s text en catal√†, que inclou:
  - Catalan General Crawling: Obtingut a partir de l'scraping dels 500 dominis .cat i .ad m√©s populars.
  - Catalan Government Crawling: Dades recopilades dels dominis .gencat i subdominis del govern catal√†.
  - Corpus p√∫blics existents: Incloent DOGC, CaWac, Open Subtitles, la Viquip√®dia catalana, entre altres.
  - Catalan News Agency: Not√≠cies de l'Ag√®ncia Catalana de Not√≠cies recopilades des de mar√ß de 2015 fins a octubre de 2020.

- **Catalan_Textual Dataset:** Un conjunt de dades espec√≠ficament creat per cobrir una √†mplia gamma de textos en catal√†.

Degut a la manca de contingut de qualitat en catal√†, tamb√© es va crear la **col¬∑lecci√≥ de datasets Patufet** utilitzant generaci√≥ de dades sint√®tiques, principalment amb el model Gemini Flash. Aquests datasets inclouen:

  - **Patufet-Textbooks:** El conjunt de dades principal amb uns 300 milions de tokens, categoritzat per sectors clau com l'educaci√≥, la ci√®ncia, la hist√≤ria i la cultura, amb submodels per a nens, secund√†ria, general, universitat i investigadors.
  
  - **Patufet-QA (Preguntes i Respostes):** Aquest conjunt de dades cont√© unes 500k preguntes amb respostes basades en el dataset Patufet-Textbooks, per donar suport a la capacitat de respondre preguntes.
  
  - **Patufet-PremiumText:** Creat utilitzant GPT-4o per garantir contingut de molta qualitat, aquest dataset inclou aproximadament 6000 exemples, com ara poemes, hist√≤ries, resums, sentiment analysis, i m√©s.
  
  - **Patufet-Human-Interactions:** Creat amb GPT-4o, aquest conjunt de dades es centra en contingut de qualitat relacionat amb interaccions humanes, com salutacions o preguntes curioses, amb pocs exemples.

Altres datasets, com ara els de programaci√≥ o seguiment d'instruccions, tamb√© es van crear. No obstant, no es van incloure en aquesta versi√≥ del model, ja que es van considerar massa avan√ßats i podien reduir la capacitat del model en tasques que no comprendria del tot.

El model base es va entrenar amb m√©s de 3000 milions de tokens √∫nics, incloent els datasets Oscar i Catalan Textual. Un cop el model va aprendre l'estructura i √∫s fonamental del catal√†, es va acabar d'entrenar amb el dataset **Patufet-Textbooks** per assegurar un coneixement molt m√©s variat i complet en diversos √†mbits. Aquest entrenament addicional va millorar molt la versatilitat i profunditat del model.

Per al model basat en instruccions, es va entrenar addicionalment amb els datasets de preguntes-respostes i instruccions per tal que pogu√©s respondre efica√ßment a missatges i seguir instruccions.

## Tokenizer

**English:**  
For this project, a specific tokenizer with 32,768 different tokens has been created using the byte pair encoding (BPE) algorithm. This tokenizer was generated using a 50 MB subset of the training data, ensuring adequate coverage of the Catalan vocabulary.

**Catal√†:**  
Per a aquest projecte, s'ha creat un tokenizer espec√≠fic amb 32,768 tokens diferents utilitzant l'algoritme byte pair encoding (BPE). Aquest tokenizer ha estat generat utilitzant un subset de 50 MB de les dades d'entrenament, assegurant una cobertura adequada del vocabulari catal√†.

## Document Structure / Estructura dels Documents

**English:**  
The following is the structure of the code repository:

**Catal√†:**  
La seg√ºent √©s l'estructura del repositori de codi:

```plaintext
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ assets
‚îÇ   ‚îú‚îÄ‚îÄ CatGPT-IT_app.py
‚îÇ   ‚îú‚îÄ‚îÄ CatGPT_app.py
‚îÇ   ‚îú‚îÄ‚îÄ CatGPT_dataset.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ CatGPT_model.py
‚îÇ   ‚îú‚îÄ‚îÄ CatGPT_train.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__
‚îú‚îÄ‚îÄ images
‚îÇ   ‚îú‚îÄ‚îÄ Dialogue_example.png
‚îÇ   ‚îú‚îÄ‚îÄ future_AI_example.png
‚îÇ   ‚îî‚îÄ‚îÄ house_example.png
‚îú‚îÄ‚îÄ logo
‚îÇ   ‚îú‚îÄ‚îÄ CatGPT.jpg
‚îÇ   ‚îî‚îÄ‚îÄ CatGPT_round.png
‚îú‚îÄ‚îÄ others
‚îÇ   ‚îú‚îÄ‚îÄ IT_model_evaluation.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ loss.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ output.txt
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ run
‚îÇ   ‚îú‚îÄ‚îÄ CatGPT-IT_run.py
‚îÇ   ‚îî‚îÄ‚îÄ CatGPT_run.py
‚îî‚îÄ‚îÄ tokenizer
    ‚îú‚îÄ‚îÄ CatGPT_tokenizer.ipynb
    ‚îú‚îÄ‚îÄ merges.txt
    ‚îî‚îÄ‚îÄ vocab.json
```

## Description of Key Files / Descripci√≥ dels Fitxers Principals

### CatGPT_tokenizer.ipynb:

- **English:** Contains the code to create and train the tokenizer for the CatGPT model.  
- **Catal√†:** Cont√© el codi per crear i entrenar el tokenizer per al model CatGPT.

### CatGPT_dataset.ipynb:

- **English:** Describes the steps to prepare the dataset used to train the model.  
- **Catal√†:** Descriu els passos per preparar el dataset utilitzat per entrenar el model.

### CatGPT_train.ipynb:

- **English:** Script to train the CatGPT model, including model configuration and hyperparameters.  
- **Catal√†:** Script per entrenar el model CatGPT, incloent configuraci√≥ del model i hiperpar√†metres.

### CatGPT_app.py:

- **English:** Script for the Streamlit app, which provides an interactive interface to generate text using the CatGPT model.  
- **Catal√†:** Script per a l'aplicaci√≥ Streamlit, que proporciona una interf√≠cie interactiva per generar text utilitzant el model CatGPT.

### CatGPT_run.py:

- **English:** Main script to launch the CatGPT app. This script handles the setup and execution of the Streamlit app.  
- **Catal√†:** Script principal per llan√ßar l'aplicaci√≥ CatGPT. Aquest script gestiona la configuraci√≥ i execuci√≥ de l'aplicaci√≥ Streamlit.

### CatGPT-IT_app.py / CatGPT-IT_run.py:

- **English:** These scripts correspond to the instruction-tuned version of the model (CatGPT-IT). The `CatGPT-IT_app.py` provides the interactive interface for text generation based on instructions or questions, while `CatGPT-IT_run.py` launches the instruction-based model.  
- **Catal√†:** Aquests scripts corresponen a la versi√≥ del model ajustat per a instruccions (CatGPT-IT). El `CatGPT-IT_app.py` proporciona la interf√≠cie interactiva per generar text basat en instruccions o preguntes, mentre que `CatGPT-IT_run.py` llan√ßa el model basat en instruccions.

### IT_model_evaluation.ipynb:

- **English:** This notebook contains the evaluation metrics and results of the instruction-tuned model (CatGPT-IT).  
- **Catal√†:** Aquest notebook cont√© les m√®triques d'avaluaci√≥ i els resultats del model ajustat per a instruccions (CatGPT-IT).

### model_evaluation.ipynb:

- **English:** Notebook to evaluate the original version of CatGPT, containing performance metrics and qualitative analyses.  
- **Catal√†:** Notebook per avaluar la versi√≥ original de CatGPT, que inclou m√®triques de rendiment i an√†lisis qualitatives.

### loss.ipynb:

- **English:** A notebook to track and analyze the loss during the training process.  
- **Catal√†:** Un notebook per fer el seguiment i analitzar la p√®rdua durant el proc√©s d'entrenament.

### output.txt:

- **English:** This file contains logs or output data from model evaluations.  
- **Catal√†:** Aquest fitxer cont√© els registres o dades de sortida de les avaluacions del model.

### requirements.txt:

- **English:** Lists the dependencies and libraries required to run the project.  
- **Catal√†:** Llista les depend√®ncies i llibreries necess√†ries per executar el projecte.

### vocab.json / merges.txt:

- **English:** These files are part of the tokenizer for the CatGPT model, containing the vocabulary and the merge rules for subword tokenization.  
- **Catal√†:** Aquests fitxers formen part del tokenizer per al model CatGPT, contenint el vocabulari i les regles de fusi√≥ per a la tokenitzaci√≥ de subparaules.

## How to Use the Model / Com Utilitzar el Model

**English:**  
To use CatGPT, you simply need to clone the repository, install the required libraries, and run the `CatGPT_run.py` or the `CatGPT-IT_run.py` script depending on the model you want to use. This script will launch the Streamlit app, where you can interact with the model through an easy-to-use interface.

**Catal√†:**  
Per utilitzar CatGPT, nom√©s cal clonar el repositori, instal¬∑lar les biblioteques necess√†ries i executar l'script `CatGPT_run.py` o `CatGPT-IT_run.py`depenent del model a utilizar. Aquest script llan√ßar√† l'aplicaci√≥ Streamlit, on podr√†s interactuar amb el model a trav√©s d'una interf√≠cie f√†cil d'usar.

## App Structure / Estructura de l'App

**English:**  
The visual app provides an intuitive interface to interact with the CatGPT model. Users can input text prompts in Catalan and receive generated text based on the model's predictions. This section covers the app's structure, its parameters, and provides visual examples.

**Catal√†:**  
L'aplicaci√≥ visual ofereix una interf√≠cie intu√Øtiva per interactuar amb el model CatGPT. Els usuaris poden introduir textos en catal√† i rebre textos generats basats en les prediccions del model. Aquesta secci√≥ cobreix l'estructura de l'aplicaci√≥, els seus par√†metres i proporciona exemples visuals.

### Overview of Parameters / Visi√≥ general dels Par√†metres

**English:**  
In the app, several parameters can be adjusted to fine-tune the model's output:
- **Max Length (tokens):** Defines the maximum number of tokens the model can generate in a single output.
- **Temperature:** Controls the randomness of predictions. Lower values make the model more deterministic.
- **Top-K:** Limits the sampling pool to the top K tokens, focusing on more probable tokens.
- **Repetition Penalty:** Applies a penalty to repeated words or phrases, reducing the likelihood of redundant text in the output.

**Catal√†:**  
A l'aplicaci√≥, es poden ajustar diversos par√†metres per afinar la sortida del model:
- **M√†xima Longitud (tokens):** Defineix el nombre m√†xim de tokens que el model pot generar en una √∫nica sortida.
- **Temperatura:** Controla l'aleatorietat de les prediccions. Valors m√©s baixos fan que el model sigui m√©s determinista.
- **Top-K:** Limita el conjunt de mostreig als K tokens m√©s probables.
- **Penalitzaci√≥ per Repetici√≥:** Aplica una penalitzaci√≥ a paraules o frases repetides, reduint la probabilitat de text redundant en la sortida.

### Example Screenshots / Captures de Pantalla d'Exemple

**English:**  
The screenshots below demonstrate how the CatGPT model performs across different tasks, showcasing both the base text generation model and the instruction-based model. The examples highlight the model's coherence, contextual awareness, and ability to generate natural Catalan text in diverse scenarios. The first example demonstrates the base model‚Äôs ability to complete a text about olive oil, while the other two examples show how the instruction-based model handles specific queries and tasks in NLP.

**Catal√†:**  
A continuaci√≥, es mostren exemples que demostren el rendiment del model CatGPT en diferents tasques, mostrant tant el model base de generaci√≥ de text com el model basat en instruccions. Els exemples il¬∑lustren la coher√®ncia, la consci√®ncia contextual i la capacitat del model per generar text natural en catal√† en diversos escenaris. El primer exemple demostra la capacitat del model base per completar un text sobre oli d‚Äôoliva, mentre que els altres dos exemples mostren com el model basat en instruccions maneja consultes espec√≠fiques i tasques en PLN.

---

<div align="center">
  <img src="examples/olive_oil.png" alt="Olive Oil Example" style="width:65%; height:auto;">
</div>

**English:**  
In this screenshot, the base model is prompted to generate text about extra virgin olive oil. The result illustrates the model‚Äôs ability to provide a coherent, informative continuation, emphasizing both the nutritional benefits of the product and its cultural significance in Spain. The output is particularly notable for its fluency and knowledge of domain-specific topics.

**Catal√†:**  
En aquesta captura de pantalla, el model base rep com a entrada un text sobre l'oli d'oliva verge extra. El resultat il¬∑lustra la capacitat del model per oferir una continuaci√≥ coherent i informativa, ressaltant tant els beneficis nutricionals del producte com la seva import√†ncia cultural a Espanya. La sortida destaca per la seva flu√Ødesa i el coneixement de temes espec√≠fics del domini.

---

<div align="center">
  <img src="examples/sentiment_analysis.png" alt="Sentiment Analysis Example" style="width:55%; height:auto;">
</div>

**English:**  
This screenshot demonstrates the instruction-based model‚Äôs ability to perform sentiment analysis. The model accurately identifies the sentiment in various sentences, providing clear, contextually appropriate responses in Catalan. This example showcases the model‚Äôs skill in natural language understanding tasks and its effective handling of user queries.

**Catal√†:**  
Aquesta captura de pantalla demostra la capacitat del model basat en instruccions per realitzar an√†lisis de sentiments. El model identifica amb precisi√≥ el sentiment en diverses frases, oferint respostes clares i adequades al context en catal√†. Aquest exemple mostra l‚Äôhabilitat del model en tasques de comprensi√≥ del llenguatge natural i la seva efic√†cia en gestionar consultes d‚Äôusuaris.

---

<div align="center">
  <img src="examples/isaac_newton.png" alt="Isaac Newton Example" style="width:65%; height:auto;">
</div>

**English:**  
In this final example, the instruction-based model generates a creative response, specifically a poem about Isaac Newton. The output demonstrates the model‚Äôs ability to generate rich, descriptive, and imaginative content in Catalan, illustrating how it can be used for more open-ended and creative text generation tasks.

**Catal√†:**  
En aquest darrer exemple, el model basat en instruccions genera una resposta creativa, concretament un poema sobre Isaac Newton. La sortida demostra la capacitat del model per generar contingut ric, descriptiu i imaginatiu en catal√†, il¬∑lustrant com pot utilitzar-se per a tasques de generaci√≥ de text m√©s obertes i creatives.

---


## Installation / Instal¬∑laci√≥

**English:**  
1. Clone this repository to your local machine:
    ```bash
    git clone https://github.com/yourusername/CatGPT.git
    cd CatGPT
    ```

2. Install the required libraries:
    ```bash
    pip install -r requirements.txt
    ```

3. Run the app:
    ```bash
    python run/CatGPT_run.py
    ```

   ```bash
   python run/CatGPT-IT_run.py
    ```

**Catal√†:**  

1. Clona aquest repositori a la teva m√†quina local:
    ```bash
    git clone https://github.com/yourusername/CatGPT.git
    cd CatGPT
    ```

2. Instal¬∑la les biblioteques necess√†ries:
    ```bash
    pip install -r requirements.txt
    ```

3. Executa l'aplicaci√≥:
    ```bash
    python run/CatGPT_run.py
    ```
   ```bash
   python run/CatGPT-IT_run.py
    ```

## Contributing / Contribucions

**English:**  
We welcome contributions to improve CatGPT. Please submit pull requests or report issues on the GitHub repository.

**Catal√†:**  
Ens agradaria molt comptar amb les vostres contribucions per millorar CatGPT. Envieu sol¬∑licituds d'extracci√≥ o informeu de problemes al repositori de GitHub.

## License / Llic√®ncia

**English:**  
This project is licensed under the MIT License.

**Catal√†:**  
Aquest projecte est√† llicenciat sota la Llic√®ncia MIT.

## Contact Information / Informaci√≥ de Contacte

**English:**  
For any inquiries or support, please contact [rogerbaigestrilla@gmail.com].

**Catal√†:**  
Per a qualsevol consulta o suport, contacteu amb [rogerbaigestrilla@gmail.com].
