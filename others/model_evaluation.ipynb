{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com actualitzar el teu armari de moda amb llaços [title] Busca blusons que tinguin un llaç en algun lloc de forma natural. [step] Aquesta és l'opció més fàcil per als tops, ja que no has de preocupar-te per crear un llaç que coincideixi amb el color i la mida del teu top. [title] Considera una blusa amb un estampat de llaços.\n",
      "Predicted Ending: [step] En lloc d'un llaç real, una blusa amb un estampat de llaços té un patró de llaços imprès. Això introdueix el llaç al teu armari d'una manera unidimensional.\n",
      "Correct Ending: [step] En lloc d'un llaç real, una blusa amb un estampat de llaços té un patró de llaços imprès. Això introdueix el llaç al teu armari d'una manera unidimensional.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com evitar que el teu fill o filla esgranqui les dents [title] Entén que l'estrès pot causar bruxisme. [step] Esgranquejar les dents pot ser un signe que el teu fill o filla està estressat o ansios sobre alguna cosa. Ajudar el teu fill o filla a relaxar-se pot ser la clau per aconseguir que deixi de rascar les dents.\n",
      "Predicted Ending: [title] Crea una rutina tranquil·la abans d'anar a dormir per al teu fill o filla. [step] Com s'ha esmentat en el pas anterior, esgranquejar les dents pot ser un signe que el teu fill o filla està estressat.\n",
      "Correct Ending: [title] Crea una rutina tranquil·la abans d'anar a dormir per al teu fill o filla. [step] Com s'ha esmentat en el pas anterior, esgranquejar les dents pot ser un signe que el teu fill o filla està estressat.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com involucrar als teus fills en la selecció d'un gos [title] Planteja la possibilitat de tenir un gos. [step] Per als nens, la idea de tenir un gos serà molt emocionant. Planteja la qüestió amb els teus fills quan tinguin temps per emocionar-se, formular preguntes i en general flipar.\n",
      "Predicted Ending: Deixa clar als teus fills que la idea de tenir un gos no és un mite complet. [substeps] En lloc de dir \"si no us podeu permetre un gos, però encara esteu disposats a provar-ne un, per què no ho proveu?\", fes saber als teus fills que la idea d'un gos és emocionant.\n",
      "Correct Ending: Podries dir \"Estem pensant en tenir un gos. Què en penses d'aquesta idea?\" [substeps] Durant aquesta conversa inicial, hauries de parlar del que hauran de fer els teus fills per cuidar del gos si decideixen tenir-ne un.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.6667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: El noiet surt corrent en diagonal i aconsegueix saltar d'esquena per sobre la barra de sis peus i la salta. després\n",
      "Predicted Ending: , el noiet aconsegueix fer quatre voltes més una altra vegada.\n",
      "Correct Ending: , més esportistes apareixen i fan el mateix salt i salten la barra sense rascar.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com ser despreocupat [title] Separa el temps de treball del temps de diversió. [step] La vida no ha de ser una tasca. Si vols aprendre a ser més despreocupat en la teva vida diària, és important dedicar temps a la diversió i mantenir-lo.\n",
      "Predicted Ending: La majoria de la gent planifica el seu dia al voltant de la feina o l'escola. És inevitable per a la majoria de nosaltres.\n",
      "Correct Ending: La majoria de la gent planifica el seu dia al voltant de la feina o l'escola. És inevitable per a la majoria de nosaltres.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com fer un llaç de regal multicapa [title] Talli una llarga peça de cinta que coincideixi amb el paper d'embolicar. [step] Ha de ser prou llarga per envoltar el regal i tenir una mica d'excés. [title] Lliga la cinta al voltant del regal.\n",
      "Predicted Ending: [step] Repeteix els passos a i d com s'ha discutit anteriorment. [title] Enganxa el llaç al paper d'embolicar.\n",
      "Correct Ending: [title] Escurça les puntes soltes en angle. [step] Ambdues puntes haurien de tenir aproximadament la mateixa llargada.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:02,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com netejar els pèsols de neu [title] Trieu pèsols sans. [step] Un pèsol de neu madur pot tenir fins a 3 polzades de longitud. Trieu aqueixos que tinguin la pell llisa, no arrugada.\n",
      "Predicted Ending: Haurien de tenir una pell de color verd sòlid sense cap esquerda. Les vagines haurien de ser prou planes, indicant que els pèsols són petitons.\n",
      "Correct Ending: Haurien de tenir una pell de color verd sòlid sense cap esquerda. Les vagines haurien de ser prou planes, indicant que els pèsols són petitons.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.5714\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com arreglar el arròs xop [title] Deixa evaporar l'aigua si hi ha aigua a la paella. [step] Treu la tapa de la paella per deixar escapar el vapor. Baixa la temperatura i continua cuinant l'arròs durant uns 5 minuts.\n",
      "Predicted Ending: [substeps] També pots afegir 3-5 gotes d'oli de te de l'arbre o d'arrel de mandioca en aquest punt per ajudar a cuinar l'arròs més ràpidament. Assegura't de posar suficient oli per cobrir el fons de la paella.\n",
      "Correct Ending: Així, l'aigua hauria quedat evaporada a la fi. [title] Escorre l'aigua sobrant amb un colador de malla fina.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:03,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Un jove filtra sorra a la mà. El vídeo es reprèn mostrant els cavalls i el camell caminant enrere. el camell\n",
      "Predicted Ending: tira del noi cap endavant, però no pot controlar el camell.\n",
      "Correct Ending: s'asseu i la gent s'aixeca del seu dors.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:03,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com evitar que el teu fill petit mossegui [title] Sàpiga que mossegar és normal. [step] El teu fill petit mossega per comunicar-se amb tú. Has de detectar el que el teu fill petit intenta dir-te i fer ajustaments.\n",
      "Predicted Ending: [substeps] Utilitza el reforç positiu per animar el teu fill petit a no mossegar. No li toquis, no el colpegis, no li estiris la cua, ni burlis-te o critiquis la conducta del teu fill petit.\n",
      "Correct Ending: Tot i que mossegar és normal, no és acceptable. Les raons típiques per mossegar inclouen: [substeps] Expressar una necessitat o sentir com ara ràbia, frustració, alegria o excitació estar aclaparat per l'entorn estar cansat estar sortint les dents experimentar copiar altres nens buscar atenció [title] Determina perquè el teu fill petit mossega.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4000\n",
      "\n",
      "Context: Un home camina cap a un camp davant d'una multitud, sosté una bola pesada en l'aire. ell\n",
      "Predicted Ending: gira, llavors llença la pilota tan lluny com pot.\n",
      "Correct Ending: gira, llavors llença la pilota tan lluny com pot.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.4545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com estilitzar un vestit de color caqui [title] Trieu un vestit basant-vos en el temps. [step] El caqui es pot portar tant en mesos càlids com freds. Quan seleccioneu un vestit de color caqui per portar, tingueu en compte el temps.\n",
      "Predicted Ending: Trieu un vestit que no sigui massa càlid o massa fred per a l'ocasió. [substeps] Per als mesos freds, proveu un vestit tejat de color caqui.\n",
      "Correct Ending: Trieu un vestit que no sigui massa càlid o massa fred per a l'ocasió. [substeps] Per als mesos freds, proveu un vestit tejat de color caqui.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:04,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com alleujar els gasos en els bebès [title] Reconèixer els símptomes dels gasos. [step] Encara que no hi ha evidència d'una connexió entre el cólic o el plor excessiu i els gasos, algunes persones poden relacionar les dues condicions. Identificar els signes dels gasos pot ajudar-vos a donar ràpidament comoditat al vostre nadó.\n",
      "Predicted Ending: Símptomes específics dels gasos inclouen: [substeps] Tendència a orinar, ronyó inflamat, dificultat per respirar, canvis en el fetus. Això pot incloure vòmits, diarrea, obstipació, inflor abdominal o dolor de panxa, mal de caps.\n",
      "Correct Ending: Els símptomes dels gasos inclouen: [substeps] Estirar les cames,  tancar els punys, remugar com si es trobés incòmode, plorar molt, fer pets, eructar. [title] Fer exercicis de bicicleta amb el bebè. [step] Si el vostre nadó sembla tenir gasos, poseu el nadó de costat a sobre una superfície estable.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4615\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:05,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com netejar els utensilis de cuina de silicona [title] Ompliu l'aixeta amb sabó i aigua. [step] Taponeu el fregador de la cuina i ompliu-lo amb aigua molt calenta, si pot ser a la temperatura que pugueu tolerar. Afegeixi unes gotes de sabó lleuger desengreixant i remeneu-ho perquè l'aigua faci bombolles.\n",
      "Predicted Ending: El sabó desengreixant està dissenyat per combatre taques difícils de netejar, com els que s'adhereixen als utensilis de cuina de silicona. [substeps] Assegureu-vos que feu servir aigua molt calenta.\n",
      "Correct Ending: El sabó desengreixant està dissenyat per combatre taques difícils de netejar, com els que s'adhereixen als utensilis de cuina de silicona. [substeps] Assegureu-vos que feu servir aigua molt calenta.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:05,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Ell està subjectant un nou tub per una roda. Agafa una bomba d'aire i la connecta a la roda. ell\n",
      "Predicted Ending: agafo la bomba de calor i la connecto al tub de cautxú.\n",
      "Correct Ending: inflo la roda amb aire.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:05,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Un home està al gimnàs amb roba esportiva, es flexiona per agafar una pesa per sobre del cap i la deixa caure de nou. ell\n",
      "Predicted Ending: la torna a alçar per sobre del cap i la deixa caure novament mentre s'allibera cap a dalt i la torna a agafar.\n",
      "Correct Ending: camina cap enrere per estirar-se abans de tornar a fer l'exercici amb més pes.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:06,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com vestir-se quan ets docent [title] Descobreix si l'escola té un codi de vestimenta establert. [step] Algunes escoles tenen un codi de vestimenta estandarditzat per als docents que defineix el que pots i el que no pots portar. Parla amb el director o amb un administrador escolar per obtenir una còpia del codi de vestimenta oficial per a docents.\n",
      "Predicted Ending: [substeps] Encara que no hi hagi un codi de vestimenta oficial, la majoria d'escoles proporcionen una llista de suggeriments per als docents sobre el que és apropiat i inapropiat de portar. [title] Inverteix en peces bàsiques com pantalons de vestir còmodes i americanes.\n",
      "Correct Ending: [substeps] Encara que no hi hagi un codi de vestimenta oficial, la majoria d'escoles proporcionen una llista de suggeriments per als docents sobre el que és apropiat i inapropiat de portar. [title] Inverteix en peces bàsiques com pantalons de vestir còmodes i americanes.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.4706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com llogar els vestits de damas d'honor [title] Determineu el vostre pressupost. [step] Abans de llogar un vestit de dama d'honor, penseu en el vostre pressupost personal. Si la festa de casament paga els vestits, haurien de ser capaços de donar-vos una idea aproximada de quant gastar.\n",
      "Predicted Ending: Si pagueu el vestit vosaltres mateixes, penseu en el vostre pressupost personal. [substeps] Penseu en quants ingressos i despeses teniu cada mes i quant sou disponible teniu.\n",
      "Correct Ending: Si pagueu el vestit vosaltres mateixes, penseu en el vostre pressupost personal. [substeps] Penseu en quants ingressos i despeses teniu cada mes i quant sou disponible teniu.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:07,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com vestir el teu nadó a la primavera [title] Escull roba en la qual el teu nadó es trobi còmode. [step] Assegura't que el teu nadó es trobi còmode quan el vesteixis per a la primavera. Els dies de primavera són més llargs i solen alternar entre fred, calor i pluja.\n",
      "Predicted Ending: És millor comprar conjunts d'abric adequats per l'hivern per al teu nadó al començament de la primavera. [substeps] Al igual que el temps pot ser càlid durant els mesos d'hivern, també hi pot haver fluctuacions de temperatura durant la primavera.\n",
      "Correct Ending: [substeps] Assegurar-te de consultar el pronòstic del temps et ajudarà a decidir el millor aspecte per vestir el teu nadó. Assegura't que la roba sigui lleugera i fresca, però que alhora pugui protegir el teu nadó de l'exposició directa al sol quan sigui a l'exterior.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4737\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:07,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com dir al teu nòvio la veritat sobre com et sents després de mesos de mentides [title] Admet la mentida a tu mateix primer. [step] Abans de poder admetre les teves mentides al teu nòvio, les has de reconèixer per tu mateix. A vegades, pots repetir una mentida una i altra vegada fins al punt que comencis a creure-la.\n",
      "Predicted Ending: Donar-te una mica d'espai i escoltar el que hauries de dir és beneficiós. [title] Decideix si vols demanar perdó al teu nòvio.\n",
      "Correct Ending: Per trencar aquest cicle, has d'admetre que hi ha un problema. [substeps] Digues-ho en veu alta a tu mateix: \"he estat deshonest amb en Matt durant molt temps ara.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:07,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com derivar la fórmula de diferència de cosinus [title] Dibuixa la teva circumferència i etiqueta-la segons sigui necessari. [title] Marca l'origen com a punt z amb el par ordenat (0,0). [title] Marca els 0 graus com a punt y amb el par ordenat (1,0).\n",
      "Predicted Ending: [title] Nomena l'equació de cosinus científicament integrada en la fórmula i utilitza les altres cel·les juntament amb la línia per determinar quina quantitat de distància és dividida. [title] Pinta l'equació de cosinus en 360 graus c/180 graus f (= k420).\n",
      "Correct Ending: [title] Dibuixa un angle especial des de la circumferència i etiqueta'l com angle a. [step] Això ens dóna el punt x, que té el par ordenat (cosa, sina).\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:08,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Una persona politja un mocador amb un dit embolicat. llavors\n",
      "Predicted Ending: , la persona treu el taló del mocador i el politja.\n",
      "Correct Ending: , la persona agafa pasta de politjar i aigua per politjar el mocador.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.4091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:08,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com portar pantalons de cigarreta [title] Escolliu una parella que caigui just sobre el turmell. [step] L'element destacat dels pantalons de cigarreta és la zona inferior de la vora. Assegureu-vos que obteniu una parella de pantalons que tingui la longitud adequada.\n",
      "Predicted Ending: Podeu trobar pantalons de cigarreta a la majoria de botigues. [substeps] La zona inferior de la vora és la zona que s'enganxa fortament quan es fa foc.\n",
      "Correct Ending: La part inferior de cada cama de pantaló hauria de caure just al damunt del turmell, ni massa llarg ni massa curt. [substeps] Si els vostres pantalons de cigarreta són massa llargs però per la resta s'ajusten bé, proveu d'ajustar-ne la vora.\n",
      "Is Correct: No\n",
      "Accuracy so far: 0.3913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:08,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [header] Com guanyar recompenses de combustible [title] Investigueu programes de recompenses de combustible. [step] Moltes gasolineres diferents, supermercats i companyies de targetes de crèdit tenen programes de recompenses de combustible. Cerqueu programes a través d'internet a la vostra zona.\n",
      "Predicted Ending: Cerqueu programes que siguin més convenients per a vosaltres, com ara un a través del supermercat o la gasolinera que visiteu més sovint, o un programa a través d'una targeta de crèdit que ja tingueu. [substeps] Llegiu atentament les condicions per saber com s'obtenen les recompenses, quin és el descompte màxim, quan caduquen les recompenses, i així successivament.\n",
      "Correct Ending: Cerqueu programes que siguin més convenients per a vosaltres, com ara un a través del supermercat o la gasolinera que visiteu més sovint, o un programa a través d'una targeta de crèdit que ja tingueu. [substeps] Llegiu atentament les condicions per saber com s'obtenen les recompenses, quin és el descompte màxim, quan caduquen les recompenses, i així successivament.\n",
      "Is Correct: Yes\n",
      "Accuracy so far: 0.4167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Perform the evaluation\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, tokenizer, dataset, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Calculate the loss only over the ending part\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 41\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39mending_input\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m):, :]  \u001b[38;5;66;03m# Get logits corresponding to the ending\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1421\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1421\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1436\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1235\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1223\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1224\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1225\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         output_attentions,\n\u001b[1;32m   1233\u001b[0m     )\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1235\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:757\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    755\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    756\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 757\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[1;32m    759\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:680\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m--> 680\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[1;32m    682\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/pytorch_utils.py:104\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    103\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[0;32m--> 104\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"baiges/CatGPT\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"baiges/CatGPT\")\n",
    "\n",
    "# Define the device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the Hellaswag dataset translated to Catalan\n",
    "with open(\"../data/ca_hellaswag.json\", 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(model, tokenizer, dataset, device):\n",
    "    total_correct = 0\n",
    "    total_items = 0\n",
    "\n",
    "    # Iterate over each entry in the dataset\n",
    "    for i, item in tqdm(enumerate(dataset)):\n",
    "        context = item['ctx']  # Get the context\n",
    "        endings = item['endings']  # Get the possible endings\n",
    "        correct_ending_idx = int(item['label'])  # Index of the correct ending\n",
    "\n",
    "        # Tokenize the context and move it to the device\n",
    "        context_input = tokenizer(context, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "        avg_loss_values = []\n",
    "        for ending in endings:\n",
    "            # Tokenize the ending and move it to the device\n",
    "            ending_input = tokenizer(ending, return_tensors=\"pt\").input_ids.to(device)\n",
    "            # Concatenate the context with each ending\n",
    "            input_ids = torch.cat([context_input, ending_input[:, 1:]], dim=-1).to(device)\n",
    "\n",
    "            # Calculate the loss only over the ending part\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                logits = outputs.logits[:, -ending_input.size(1):, :]  # Get logits corresponding to the ending\n",
    "                loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "                shift_logits = logits[:, :-1, :].contiguous()\n",
    "                shift_labels = ending_input[:, 1:].contiguous()\n",
    "                loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "                avg_loss = loss.mean().item()  # Calculate the average loss per token\n",
    "                avg_loss_values.append(avg_loss)\n",
    "\n",
    "        # Find the ending with the lowest average loss per token\n",
    "        predicted_idx = torch.argmin(torch.tensor(avg_loss_values)).item()\n",
    "\n",
    "        # Check if the prediction is correct and update the counters\n",
    "        is_correct = predicted_idx == correct_ending_idx\n",
    "        if is_correct:\n",
    "            total_correct += 1\n",
    "        total_items += 1\n",
    "\n",
    "        # Calculate the accuracy for this specific item\n",
    "        item_accuracy = total_correct / total_items\n",
    "\n",
    "        # Print context, prediction, correctness, and accuracy for this item\n",
    "        print(f\"Context: {context}\")\n",
    "        print(f\"Predicted Ending: {endings[predicted_idx]}\")\n",
    "        print(f\"Correct Ending: {endings[correct_ending_idx]}\")\n",
    "        print(f\"Is Correct: {'Yes' if is_correct else 'No'}\")\n",
    "        print(f\"Accuracy so far: {item_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Calculate the overall accuracy\n",
    "    accuracy = total_correct / total_items\n",
    "    return accuracy\n",
    "\n",
    "# Perform the evaluation\n",
    "accuracy = evaluate_model(model, tokenizer, dataset, device)\n",
    "print(f\"Final Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
